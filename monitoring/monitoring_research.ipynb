{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mAdam\u001b[39;00m \n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dataloader \n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataloaders\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utilities'"
     ]
    }
   ],
   "source": [
    "import math \n",
    "from pathlib import Path \n",
    "from types import SimpleNamespace\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as Adam \n",
    "from torch.utils.data import dataloader \n",
    "from utilities import get_dataloaders\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 3 * 16 * 16\n",
    "OUTPUT_SIZE = 5 \n",
    "HIDDEN_SIZE = 256 \n",
    "NUM_WORKERS = 2 \n",
    "CLASSES = [\"hero\", \"non-hero\", \"food\", \"spell\", \"side-facing\"]\n",
    "DATA_DIR = Path(\"./data/\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dropout):\n",
    "    \"Simple MLP with Dropout\"\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
    "        nn.BatchNorm1d(HIDDEN_SIZE),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config object to store hyperparameters\n",
    "config = SimpleNamespace(   \n",
    "    epochs=2,\n",
    "    batch_size=128,\n",
    "    lr = 1e-5,\n",
    "    dropout = 0.5,\n",
    "    slice_size = 10_000,\n",
    "    valid_pct = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"Train a model with a given config\"\n",
    "\n",
    "    wandb.init(project = \"eval_crypo_performance\", config = config)\n",
    "\n",
    "    # Get the data \n",
    "    train_dl, valid_dl = dataloader(DATA_DIR, config)\n",
    "\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / train_dl.batch_size)\n",
    "\n",
    "    model = get_model(config)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr = config.lr)\n",
    "\n",
    "    example_ct = 0 \n",
    "\n",
    "    for epoch in tqdm(range(config.epochs), total=config.epochs): \n",
    "        model.train()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            example_ct += len(images)\n",
    "            metrics = {\n",
    "                \"train/train_loss\": train_loss,\n",
    "                \"train/epoch\": epoch + 1,\n",
    "                \"train/example_ct\": example_ct\n",
    "            }\n",
    "            wandb.log(metrics)\n",
    "\n",
    "        # compute validation metrics\n",
    "        val_loss, accuracy = validate_model(model, valid_dl, loss_func)\n",
    "        val_metrics = {\n",
    "            \"val/val_loss\": val_loss,\n",
    "            \"val/accuracy\": accuracy\n",
    "        }\n",
    "        wandb.log(val_metrics)\n",
    "    \n",
    "    wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_dl, loss_func):\n",
    "    \"Compute the performance of the model on the validation set\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0 \n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels) * labels.size(0)\n",
    "\n",
    "            # compute accuracy and accumulate \n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleoncen0-iga\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/lnshuti/Desktop/portfolio/meta-labelling-architecture/monitoring/wandb/run-20230803_121631-m4aq2th3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leoncen0-iga/eval_crypo_performance/runs/m4aq2th3' target=\"_blank\">splendid-universe-1</a></strong> to <a href='https://wandb.ai/leoncen0-iga/eval_crypo_performance' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leoncen0-iga/eval_crypo_performance' target=\"_blank\">https://wandb.ai/leoncen0-iga/eval_crypo_performance</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leoncen0-iga/eval_crypo_performance/runs/m4aq2th3' target=\"_blank\">https://wandb.ai/leoncen0-iga/eval_crypo_performance/runs/m4aq2th3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(config)\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      4\u001b[0m wandb\u001b[39m.\u001b[39minit(project \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meval_crypo_performance\u001b[39m\u001b[39m\"\u001b[39m, config \u001b[39m=\u001b[39m config)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Get the data \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_dl, valid_dl \u001b[39m=\u001b[39m dataloader(DATA_DIR, config)\n\u001b[1;32m      9\u001b[0m n_steps_per_epoch \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mceil(\u001b[39mlen\u001b[39m(train_dl\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m train_dl\u001b[39m.\u001b[39mbatch_size)\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m get_model(config)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.lr = 1e-4\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dropout = 0.1 \n",
    "config.epochs = 1 \n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.lr = 1e-3\n",
    "train_model(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
